# Setup
```{r}
library("tidyverse")
library("ggplot2")
```

# Problem 8.2
```{r}
data <- read.csv("Ch08.Ex2.PeaceCorpsData/PeaceCorpsHW.csv")
```

## Problem A
Intuitively, it makes sense that people would be more likely to apply to the peace corps when the economy is doing poorly. When the economy is booming, it is easier for young people to get jobs, so they have more options. When there are fewer job options, some young people may be swayed to apply to the Peace Corps.

## Problem B
```{r}
TwoB <- lm(appspc ~ unemployrate + yr1 + yr2 + yr3 + yr4 + yr5 + yr6, data=data)
summary(TwoB)
```
For each one unit increase in the unemployment rate, there is a corresponding 1.107 increase in the conditional mean of peace orpos applications. The coefficient is not statistically significant. It seems plausible that the relationship between applications and unemployment is different between states due to time-invariant factors (e.g. people in Mississippi may be more inclined to apply to the peace corps than people in Alabama for some reason), so a better model may include fixed effects on state.


## Problem C
```{r}
ggplot(data, aes(x=unemployrate, y=appspc)) + geom_text(aes(label=stateshort))
# Referenced an online ggplot tutorial to create the plot
# Citation
# "Introduction to R Graphics with Ggplot2." Harvad.edu. Harvard University, n.d. Web. 3 June 2017. <http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html>.
# Also referenced a Stack Overflow Post in creating this plot
# Reference
# "Label Points in Geom_point." Stack Overflow. Stack Exchange Inc., n.d. Web. 3 June 2017. <https://stackoverflow.com/questions/15624656/label-points-in-geom-point>. Referenced the answer by username "agstudy" on (answer was edited by username "micstr" on July 31, 2016)
```
The graph makes the points from the District of Columbia really stick out. We can also run the model with fixed effects on state to see how the coefficinet on DC is different from the coefficients on other states.

```{r}
TwoC <- lm(appspc ~ unemployrate + factor(state) + yr1 + yr2 + yr3 + yr4 + yr5 + yr6, data=data)
summary(TwoC)
```
The coefficient on the District of Columbia is quite a bit higher (almost three times higher than the next highest state coefficient). The high coefficient on District of Columbia means that the mean value of appspc is quite a bit higher in the District of Columbia than in the other states. How might this affect the pooled regression? My guess is that the coefficient on umemployrate will be much higher in the pooled regression with DC included than without DC included, because the Y-values for the DC points are much higher than the Y-values for the other states' points. As the output below shows, the unemployrate coefficient is far lower in the pooled regression without DC (-1.964) than with DC (1.107).

```{r}
no_DC <- subset(data, state != "DISTRICT OF COLUMBIA")
# referenced documentation on subset -- http://www.statmethods.net/management/subset.html -- to write the code to subset DC
# Citation: "Subsetting Data." Quick - R. Robert I. Kabacoff, Ph.D., n.d. Web. 3 June 2017. <http://www.statmethods.net/management/subset.html>.


check_no_DC <- lm(appspc ~ unemployrate + yr1 + yr2 + yr3 + yr4 + yr5 + yr6, data=no_DC)
summary(check_no_DC)
```

We can also look at the scatterplot with and without DC. The scatter looks dramatically different without DC than it did with DC. The slight positive slope of the regression line is now a slight negative slope.
```{r}
ggplot(no_DC, aes(x=unemployrate, y=appspc)) + geom_text(aes(label=stateshort))
# Referenced an online ggplot tutorial to create the plot
# Citation
# "Introduction to R Graphics with Ggplot2." Harvad.edu. Harvard University, n.d. Web. 3 June 2017. <http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html>.
# Also referenced a Stack Overflow Post in creating this plot
# Reference
# "Label Points in Geom_point." Stack Overflow. Stack Exchange Inc., n.d. Web. 3 June 2017. <https://stackoverflow.com/questions/15624656/label-points-in-geom-point>. Referenced the answer by username "agstudy" on (answer was edited by username "micstr" on July 31, 2016)
```

## Problem D
```{r}
no_DC_pooled <- lm(appspc ~ unemployrate + yr1 + yr2 + yr3 + yr4 + yr5 + yr6, data=no_DC)
summary(no_DC_pooled)
```
As shown in Part C, the coefficient on unemployrate went from beign positive to negative. For each one unit increase in the unemployment rate without DC's data points, there is a 1.964 unit decrease in in appspc. The coefficient is statistically significant at the alpha = .15 level.

## Problem E
The results change significantly. The coefficient in the pooled regression is -1.964, versus 0.8125 in the fixed effects model. The fixed effects model is preferable in my opinion. Controlling for fixed effects controls for time invariant variables that could confound the relationship between unemployment rate and applications (e.g. perhaps people in DC are more likely to apply to the Peace Corps than people in Alabama for whatever reason). In addition, the fixed effect on year controls for time period effects (i.e. effects that change the number of applications in a year across all states).
```{r}
no_DC_fixed <- lm(appspc ~ unemployrate + factor(state) + factor(year), data=no_DC)
summary(no_DC_fixed)
```

## Problem F
```{r}
# I used code from Bailey's chapter 8 computing corner to run this code
library(plm)
plm(appspc ~ unemployrate, data=no_DC, index=c("state", "year"), model="within", effect="twoways")
```
The coefficient on unemployrate is the same using the de-meaned approach or the LSDV approach.


# Problem 8.5
```{r}
school_data <- read.csv("Ch08.Ex5.TexasSchoolBoardsData/TexasSchoolBoard.csv")
```

## Problem A
```{r}
FiveA <- lm(LnAvgSalary ~ OnCycle, data=school_data)
summary(FiveA)
```
OnCycle is a dichotomous variable that can take values 0 or 1. The coefficient on OnCycle denotes the change in the conditional mean of logged, average teacher salaries when the election takes place on a full cycle. Since LnAvgSalary is the logged average salary, we know that a one unit increase in OnCycle causes a 3.06% decrease in average teacher salary in all districts. There could be bias in our estimates if there are omitted variables (e.g. period effects that cause the average logged, average teacher salary to differ between years). 

If districts in which the teacher unions are more powerful are more able to get off cycle elections, then there could be some bias caused by reverse causality. I would assume that the power of teacher unions is correlated with salary. If that is the case, then the power of unions is a confounder, since it is correlated with both OnCycle and LnAvgSalary.

## Problem B
```{r}
# Referenced Bailey's "Computing Corner" for Chapter 8 to write this code
FiveB <- lm(LnAvgSalary ~ CycleSwitch + AfterSwitch + AfterCycleSwitch, data=school_data)
summary(FiveB)
```
The coefficients tell us several things. The coefficient on CycleSwitch tells us the difference in the intercepts between the districts that switched and did not switch. That is, among districts that switched, LnAvgSalary was .024 lower than among districts that did not switch. The coefficient on AfterSwtich provides the difference in the conditional mean of Y after 2007 versus before 2007. The interaction term provides the difference in difference. In the post-2007 time period, the change in average teacher salary among districts that switched to OnCycle elections was .86% lower than the change in districts that did not switch.

The effect of moving to on-cycle elections on salary appears to be negative. That is, on-cycle elections made teacher salaries increase by a smaller amount than they otherwise would have if the districts that switched had not switched. I do not know if we can say anything about the type of districts that switched. The salaries in all districts are higher after 2007 than before 2007, but the increase was more marked in districts that did not switch.


## Problem C
```{r}
FiveC <- lm(LnAvgSalary ~ OnCycle + factor(DistNumber), data=school_data)
summary(FiveC)
```

The results show that the conditional mean of LnAvgSalary is .08% higher among districts that are on cycle versus off cycle. The coefficient is not statistically significant. Since time fixed effects are not included, period effects (e.g. an effect that would cause a change in teacher salaries in all of the districts) are not controlled for.

## Problem D
```{r}
FiveD <- lm(LnAvgSalary ~ OnCycle + factor(DistNumber) + factor(Year), data=school_data)
summary(FiveD)
```
The conditional mean of LnAvgSalary is .85% lower among districts that are OnCycle versus districts that are off cycle. The coefficient is statistically significant.

### Problem Di
Since district fixed effects are included, any characteristics that are specific to districts that do not change over time will be controlled for. So, preexisting characteristics that do not change between 2003 and 2009 will be controlled for. 

### Problem Dii
Period effects that affect all districts are controlled for by including Year fixed effects.

## Problem E
No. We would certainly still be able to compare the conditional mean of LnAvgSalary among districts that are on or off cycle. However, that comparison would not be particularly useful, unless we included some omitted variables (e.g. power of teacher unions). The useful part of using the diff in diff or two-way fixed effects approach is that we are able to see how salaries changed in districts that did not switch versus districts that did switch. We can then use the comparison to determine the effect of holding elections on cycle. The comparison is useful as long as we are comfortable assuming that the change in teacher salaries among districts that did switch would have mirrored the change among districts that did not switch had the districts that switched not switched.


# Problem 11.3
```{r}
congress_data <- read.csv("Ch11.Ex3.CongressionalElectionsData/CongressRD.csv")
```

## Problem A
As mentioned in the equation, politicians may try to appeal to median voters, as opposed to strictly adhering to their party's views on all issues. In addition, there are some omitted variables that could change a politician's ideology regardless of party (e.g. a Republican that loves the outdoors may be more likely to support environmental regulations than other republicans, so love of the outdoors could be an omitted variable).

## Problem B
RD models can fight endogeneity because they do not require that politicial party not be correlated with the error term. The inclusion of an assignment variable on the right hand side of the equation eliminates any potential correlation between the error terms and political party.

## Problem C
```{r}
ggplot(congress_data, aes(x=GOP2party2010, y=Ideology)) + geom_point()
# Referenced an online ggplot tutorial to create the plot
# Citation
# "Introduction to R Graphics with Ggplot2." Harvad.edu. Harvard University, n.d. Web. 3 June 2017. <http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html>.
# Also referenced a Stack Overflow Post in creating this plot
# Reference
# "Label Points in Geom_point." Stack Overflow. Stack Exchange Inc., n.d. Web. 3 June 2017. <https://stackoverflow.com/questions/15624656/label-points-in-geom-point>. Referenced the answer by username "agstudy" on (answer was edited by username "micstr" on July 31, 2016)
```
There is a sharp discontinuity where GOP2party2010 is equal to .5. More specifically, in districts where more than 50% of the votes went to the Republican candidate, political ideology tended to have a much higher score. Slopes on both sides of the discontinuity seem to positive. I think that the RD will show that ideology scores tend to be closer to 0 in districts where GOP2party2010 is close to .5 and further from 0 where the margin of victory was larger.

## Problem D
The assignment variable is GOP2party2010. The treatment variable is a Republican win, where the treatment is 1 if the assignment variable is greater than or equal to .5 and 0 otherwise.

The most basic RD model would entail keeping the slopes of the regression lines the same across the discontinuity. The following formula would describe such a relationship:

$$
\text{Ideology} = \beta_0 + \beta_{1}\text{GOPwin2010}_i + \beta_{2}\text{GOP2party2010}_i + \epsilon_i
$$
Beta-knot is the intercept for the first line; that is where the non-treatment group regression line crosses the y-axis. Beta1 is the difference between the intercept of the non-treatment group regression line and the treatment group regression line. Beta2 is the slope paratmeter for each line.

## Problem E
```{r}
simple_rd <- lm(Ideology ~ GOPwin2010 + GOP2party2010, data=congress_data)
summary(simple_rd)
# Citation: Bailey's Chapter 8 Computing Corner
```
The intercept coefficient states that the non-treatment group regression line crosses the y-axis at -.48. the treatment group regression line crosses the y-axis at .52 (1-.48). The conditional mean Ideology score is 1 higher in districts in which a republican narrowly won versus a district where a republican narrowly lost, indicating an effect of 1 due to being republican. The coeffecient on GOP2party2010 states that the slope of each line is .23; for each one unit increase in GOP2party2010, there is a corresponding .23 increase in the conditional mean ideology score.


## Problem F
The equation is now:
$$
\text{Ideology} = \beta_0 + \beta_{1}\text{GOPwin2010}_i + \beta_{2}\text{(GOP2party2010}_i - .5) + \beta_3\text{(GOP2party2010}_i - .5)\text{GOPwin2010}_i +  \epsilon_i
$$
```{r}
diff_slopes <- lm(Ideology ~ GOPwin2010 + assignment_var + assignment_var*GOPwin2010, data=congress_data)
summary(diff_slopes)
```
The beta-knot and GOPWin2010 coefficients are pretty similar. The coefficient on assignment_var is more than twice as high. The coefficient on assignment_var now encapsulates the slope of the non-treated group regression line. The slope is much higher in the non-treated group than in the treated group, hence the change in this variable. The coefficient on the interaction term is negative, which shows that the slope is .49 lower in the treated group.

```{r}
# nulls deleted
congress_data <- na.omit(congress_data)
congress_data$fitted <- predict(diff_slopes)
ggplot(congress_data, aes(x=assignment_var, y=Ideology)) + geom_point() + geom_line(aes(y=fitted))
# Referenced an online ggplot tutorial to create the plot and use the predict function
# Citation
# "Introduction to R Graphics with Ggplot2." Harvad.edu. Harvard University, n.d. Web. 3 June 2017. <http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html>.
# Also referenced R documentation while figuring out how to work with the predict function
# Citation
# "Predict Method for Linear Model Fits." R Documentation. N.p., n.d. Web. 4 June 2017. <https://stat.ethz.ch/R-manual/R-devel/library/stats/html/predict.lm.html>. [Package stats version 3.4.0 Index]
```

### Democrat with GOP2party2010 = 0
The fitted value for a democrat with GOP2party2010=0 is -.58.

```{r}
 -0.31327 - (.5 * 0.52861)
# [1] -0.577575
```

### Democrat with GOP2party2010=.5
The value is given by our regression. It is the coefficient on beta-knot, approximately -0.31.

### Republican with GOP2party2010=.5
The value is also given by our regression. It is the coefficient on beta-knot + the coefficient on GOPwin2010, approximately .67. 
```{r}
-0.31327 + 0.98157
# [1] 0.6683
```

### Republican with GOPparty2010=1
We can calculate the value similarly to how we calculated the fitted ideology score for a democrat where GOP2party2010=0. The ideology score for a republican where GOP2party2010=1 is about .69.
```{r}
0.6683 + (.5 * (0.52861 - 0.48933))
# [1] 0.68794
```

## Problem G
The equation is now:
$$
\text{Ideology} = \beta_0 + \beta_{1}\text{GOPwin2010}_i + \beta_{2}\text{(GOP2party2010}_i) + \beta_3\text{(GOP2party2010}_i)\text{GOPwin2010}_i +  \epsilon_i
$$
```{r}
diff_slopes2 <- lm(Ideology ~ GOPwin2010 + GOP2party2010 + GOP2party2010*GOPwin2010, data=congress_data)
summary(diff_slopes2)
```
Both of the slope coefficients remain unchanged, as is to be expected. Both of the intercept coefficients are higher, which makes sense because each data point in our assignment variable is .5 higher in this model compared to the previous model.

```{r}
# nulls deleted
congress_data <- na.omit(congress_data)
congress_data$fitted <- predict(diff_slopes2)
ggplot(congress_data, aes(x=GOP2party2010, y=Ideology)) + geom_point() + geom_line(aes(y=fitted))
# Referenced an online ggplot tutorial to create the plot and use the predict function
# Citation
# "Introduction to R Graphics with Ggplot2." Harvad.edu. Harvard University, n.d. Web. 3 June 2017. <http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html>.
# Also referenced R documentation while figuring out how to work with the predict function
# Citation
# "Predict Method for Linear Model Fits." R Documentation. N.p., n.d. Web. 4 June 2017. <https://stat.ethz.ch/R-manual/R-devel/library/stats/html/predict.lm.html>. [Package stats version 3.4.0 Index]
```

### Democrat with GOP2party2010 = 0
The fitted value for a democrat with GOP2party2010=0 is -0.841885.

```{r}
 -0.57758 - (.5 * 0.52861)
# [1] -0.841885
```

### Democrat with GOP2party2010=.5
The value is given by our regression. It is the coefficient on beta-knot, approximately -0.58.

### Republican with GOP2party2010=.5
The value is also given by our regression. It is the coefficient on beta-knot + the coefficient on GOPwin2010, approximately .65. 
```{r}
-0.57758 + 1.2262
# [1] 0.64862
```

### Republican with GOPparty2010=1
We can calculate the value similarly to how we calculated the fitted ideology score for a democrat where GOP2party2010=0. The ideology score for a republican where GOP2party2010=1 is about .67.
```{r}
0.64862 + (.5 * (0.52861 - 0.48933))
# [1] 0.66826
```

The fitted values are very similar to the fitted values from part F for republicans. They are quite a bit lower for democrats in part G versus part F. I would guess that the values are more similar for Republicans than for Democrats in parts F and G because the slope for Republicans is much lower than the slope for Democrats, so changing the GOP2party2010 values has less of an effect on the Republican fitted values than on the Democrat fitted values.

## Problem H
Bailey discusses a potential test to determine if clustering is present. Bailey suggests creating a histogram, which is a useful, easy check to see if clustering exists. Plotting a histogram does not seem to identify an obvious clustering.
```{r}
ggplot(congress_data, aes(x=assignment_var)) + geom_histogram()
# Referenced an online ggplot tutorial to create the histogram
# Citation
# "Introduction to R Graphics with Ggplot2." Harvad.edu. Harvard University, n.d. Web. 3 June 2017. <http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html>.
```

## Problem I
Bailey  recommends determining if the treatment causes a discontinuity in other variables, with the argument being that if that is the case, then the treatment is not the only thing affected by the treatment. If other variables are affected by the treatment, then RD may not be an appropriate method for analyzing the question of interest. 

### Child Poverty
```{r}
check1 <- lm(ChildPoverty ~ GOPwin2010 + GOP2party2010 + GOP2party2010*GOPwin2010, data=congress_data)
summary(check1)
```

### Median Income
```{r}
check2 <- lm(MedianIncome ~ GOPwin2010 + GOP2party2010 + GOP2party2010*GOPwin2010, data=congress_data)
summary(check2)
```

### Obama2008
```{r}
check3 <- lm(Obama2008 ~ GOPwin2010 + GOP2party2010 + GOP2party2010*GOPwin2010, data=congress_data)
summary(check3)
```

### WhitePct
```{r}
check4 <- lm(WhitePct~ GOPwin2010 + GOP2party2010 + GOP2party2010*GOPwin2010, data=congress_data)
summary(check4)
```

Since the coefficient on GOPwin2010 is significant in each regression, there is a significant discontinuity where GOP2party2010=.5 in each regression. That means that the treatment is correlated with the treatment. Therefore, ChildPoverty, MedianIncome, Obama2008, and WhitePct should all be included as variables on the right hand side of the equation, since we want Ideology to be the only variable that is affected by the treatment.

## Probm J
```{r}
diff_slopes3 <- lm(Ideology ~ GOPwin2010 + GOP2party2010 + GOP2party2010*GOPwin2010 + ChildPoverty + MedianIncome + Obama2008 + WhitePct, data=congress_data)
summary(diff_slopes3)
```
The coefficient on GOPwin2010 is about 1.05, meaning that the mean Ideology is about 1.05 higher at GOP2party2010=.5 for Republicans than Democrats. Including the new variables on the right hand side equation means that any changes in ChildPoverty, MedianIncome, Obama2008, and WhitePct resulting from the treatment are controlled for.

## Problem K
```{r}
congress_data$squared_int <- (congress_data$GOP2party2010*GOPwin2010) ^2
quad <- lm(Ideology ~ GOPwin2010 + GOP2party2010 + GOP2party2010 + GOP2party2010*GOPwin2010 + squared_int + ChildPoverty + MedianIncome + Obama2008 + WhitePct, data=congress_data)
# Citation: Bailey's Chapter 7 Computing Corner. Referenced the Chapter 7 computing corner to figure out how to make a quadratic term
summary(quad)
```
The shape of the regression line may change when using a quadratic function, but the coefficient on GOPwin2010 is basically the exact same as it was in part J. The fitted values, especially as we move further away from GOP2party2010=.5, will be quite different. The beta-knot value is also different, as is to be expected by changing the slope of the non-treated regression line.

## Problem L
```{r}
window <- subset(congress_data, GOP2party2010 > .4)
window <- subset(window, GOP2party2010 < .6)
# referenced documentation on subset -- http://www.and statmethods.net/management/subset.html -- to write the code to subset congress_data
# Citation: "Subsetting Data." Quick - R. Robert I. Kabacoff, Ph.D., n.d. Web. 3 June 2017. <http://www.statmethods.net/management/subset.html>.

window_model <- lm(Ideology ~ GOPwin2010 + GOP2party2010 + GOP2party2010*GOPwin2010  + ChildPoverty + MedianIncome + Obama2008 + WhitePct, data=window)
summary(window_model)
```
The coefficient on GOP2party2010 is slightly lower than the model from part j (1.201 vs 1.051). The difference in slopes in the treated and non-treated groups is slightly lower ( -.6745 vs -.1771).

## Problem M
The model in part l is the most credible. There are a good number of data points in the narrow window and all it includes several control variables that should be controlled for. The data does not seem to need a quadratic fit, especially in such a narrow window.


# Problem 11.4
```{r}
headstart <- read.csv("Ch11.Ex4.HeadStartNationalData/LudwigMiller_head_start.csv")
```

## Problem A
The equation is:
$$
\text{Mortality} = \beta_0 + \beta_{1}\text{Headsart}_i + \beta_{2}\text{Poverty}_i + \epsilon_i
$$
As opoposed to drawing, I will explain what I think the graph will look like. I would assume that counties where the poverty level is slightly below 59.2% would have slightly lower mortality rates than areas where the poverty level is slightly above 59.2%. I would expect that the slope will be positive non-linear to the left of the cutoff, where increasing income leads to a decrease in mortality. I would expect the data to the left of the cutoff to exhibit diminishing marginal returns to health as income increases. To the right of the cutoff, I would expect for the line to be non-linear, since there are diminishing marginal returns to mortality as wealth increases significantly (e.g. people that make 100,000 dollars per year are not likely to be significantly less healthy than people that make 150,000 dollars per year, whereas I would expect that someone who makes 50,000 dollars per year is significantly healthier than someone who makes 0 dollars per year).

## Problem B
Regression discontinuity can help explain causation since including the assignment variable on the right side of the equation can ensure that the coefficient on the treatment variables is exogenous.

## Problem C
```{r}
FourC <- lm(Mortality ~ HeadStart + Poverty, data=headstart)
summary(FourC)
```
The coefficient on HeadStart indicates that the mean mortality rate is .9131 lower at the discontinuity for the treated group, indicating that HeadStart may have some beneficial impact on mortality.

## Probem D
```{r}
FourD <- lm(Mortality ~ HeadStart + Poverty + HeadStart*Poverty, data=headstart)
summary(FourD)
```
The coefficient on the interaction term indicates that the slope on the regression line in the treated group is .18 higher than the slope of the regression line in the non-treated group. The coefficient on HeadStart is similar in the simple and varying slopes models (-1.02678 and -0.91310, respectively).

## Problem E
```{r}
headstart_window <- subset(headstart, Poverty > -.8)
headstart_window <- subset(headstart_window, Poverty < .8)
# referenced documentation on subset -- http://www.and statmethods.net/management/subset.html -- to write the code to subset congress_data
# Citation: "Subsetting Data." Quick - R. Robert I. Kabacoff, Ph.D., n.d. Web. 3 June 2017. <http://www.statmethods.net/management/subset.html>.
FourE <- lm(Mortality ~ HeadStart + Poverty, data=headstart_window)
summary(FourE)
```
The smaller model using the smaller window seems to indicate an even larger benefit conferred (a -2.1035 reduction in mortality at the cut point).

## Problem F
```{r}
quad <- lm(Mortality ~ HeadStart + Poverty + HeadStart*Poverty + I((HeadStart*Poverty)^2), data=headstart)
# Citation: Bailey's Chapter 7 Computing Corner. Referenced the Chapter 7 computing corner to figure out how to make a quadratic term
summary(quad)
```

## Problem G
```{r}
ggplot(headstart, aes(x=Poverty, y=Mortality)) + geom_point()
# Referenced an online ggplot tutorial to create the plot
# Citation
# "Introduction to R Graphics with Ggplot2." Harvad.edu. Harvard University, n.d. Web. 3 June 2017. <http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html>.
# Also referenced a Stack Overflow Post in creating this plot
# Reference
# "Label Points in Geom_point." Stack Overflow. Stack Exchange Inc., n.d. Web. 3 June 2017. <https://stackoverflow.com/questions/15624656/label-points-in-geom-point>. Referenced the answer by username "agstudy" on (answer was edited by username "micstr" on July 31, 2016)
```
```{r}
ggplot(headstart_window, aes(x=Poverty, y=Mortality)) + geom_point()
# Referenced an online ggplot tutorial to create the plot
# Citation
# "Introduction to R Graphics with Ggplot2." Harvad.edu. Harvard University, n.d. Web. 3 June 2017. <http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html>.
# Also referenced a Stack Overflow Post in creating this plot
# Reference
# "Label Points in Geom_point." Stack Overflow. Stack Exchange Inc., n.d. Web. 3 June 2017. <https://stackoverflow.com/questions/15624656/label-points-in-geom-point>. Referenced the answer by username "agstudy" on (answer was edited by username "micstr" on July 31, 2016)
```
I do not see a discernible discontinuity when I look at the full dataset or at the smaller window (where we only look at points where poverty is greater than -.8 or less than .8).

## Problem H
```{r}
ggplot(headstart_window, aes(x=Bin, y=BinMean)) + geom_point()
# Referenced an online ggplot tutorial to create the plot
# Citation
# "Introduction to R Graphics with Ggplot2." Harvad.edu. Harvard University, n.d. Web. 3 June 2017. <http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html>.
# Also referenced a Stack Overflow Post in creating this plot
# Reference
# "Label Points in Geom_point." Stack Overflow. Stack Exchange Inc., n.d. Web. 3 June 2017. <https://stackoverflow.com/questions/15624656/label-points-in-geom-point>. Referenced the answer by username "agstudy" on (answer was edited by username "micstr" on July 31, 2016)
```
Binning is often useful to idenfy a discontinuity. I think our bins might be too large in this case, but they seem to show the opposite of what I would have expected; the graph shows that the mortality rate is higher just to the left of the discontinuity compared to just the right of the discontinuity.

## Problem I
```{r}
ggplot(headstart_window, aes(x=Bin, y=BinMean)) + geom_point() + geom_smooth(aes(y=FittedQuadratic))
# Referenced an online ggplot tutorial to create the plot and use the predict function
# Citation
# "Introduction to R Graphics with Ggplot2." Harvad.edu. Harvard University, n.d. Web. 3 June 2017. <http://tutorials.iq.harvard.edu/R/Rgraphics/Rgraphics.html>.
# Also referenced R documentation while figuring out how to work with the predict function
# Citation
# "Predict Method for Linear Model Fits." R Documentation. N.p., n.d. Web. 4 June 2017. <https://stat.ethz.ch/R-manual/R-devel/library/stats/html/predict.lm.html>. [Package stats version 3.4.0 Index]
```
I used the FittedQuadratic values that were already included in the dataset. The curve seems to show that mortality is lowest where bin=.25 and highest around bin=-.3 and bin=.8. I'm honestly not sure what to make of these results, since they seem to indicate that the poorest neighborhoods have a lower mortality than the least poor neighborhoods. My guess is that that there is an underlying data issue (e.g. small sample size).

# Problem 13.3
```{r}
bikedata <- read.csv("Ch13.Ex1.BikeShareData/BikeShare.csv")
```

## Problem A
```{r}
# using code from Bailey's Chapter 13 computing corner
OneA <- lm(trips ~ lowtemp + weekend, data=bikedata)
summary(OneA)
Errors <- resid(OneA)
LagErrors<- c(NA, Errors[1:(length(Errors)-1)])
AuxReg <- lm(Errors ~ LagErrors)
summary(AuxReg)
```
Since the coefficient on LagErrors is not statistically significant, we cannot say that there is autocorrelation in the data.

## Problem B
```{r}
# using code from Bailey's Chapter 13 computing corner
Rho_hat <- summary(AuxReg)$coefficients[2]
bikedata$lag_lowtemp <- c(NA, bikedata$lowtemp[1:nrow(bikedata) -1])
bikedata$lag_trips <- c(NA, bikedata$trips[1:nrow(bikedata) -1])
bikedata$lag_weeekend <- c(NA, bikedata$weekend[1:nrow(bikedata) -1])

bikedata$lowtemp_rho <- bikedata$lowtemp - Rho_hat*lag_lowtemp
bikedata$trips_rho <- bikedata$trips - Rho_hat*lag_trips
bikedata$weekend_rho <- bikedata$weekend - Rho_hat*lag_weeekend

summary(lm(trips_rho~lowtemp_rho + weekend_rho, data=bikedata))
```
I'm not sure why my coefficients are a bit lower than my coefficients from the first regression. I don't think they should be, since autocorrelation does not bias beta coefficients. Rather, the autocorrelation corrected model should have the same coefficients, but wider confidence intervals (we do see wider confidence intervals in the autocorrelation corrected model). Maybe the fact that I didn't actually see any autocorrelation in Part A is the cause of the surprising results.

# Problem 
